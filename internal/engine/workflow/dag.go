package workflow

import (
	"context"
	"crypto/md5"
	"encoding/json"
	"fmt"
	"sort"
	"strings"
	"sync"
	"sync/atomic"
	"time"
)

// DAG æ•´ä¸ªå›¾
type DAG struct {
	nodes     map[ID]*Node
	mu        sync.RWMutex
	failed    atomic.Bool        // å…¨å±€å¤±è´¥æ ‡è®°
	cancelAll context.CancelFunc // cancelAll å–æ¶ˆæ‰€æœ‰èŠ‚ç‚¹
	// ç¼“å­˜ä¼˜åŒ–
	topologyCache []ID        // ç¼“å­˜çš„æ‹“æ‰‘åº
	topologyValid atomic.Bool // æ‹“æ‰‘åºç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
	layersCache   [][]ID      // ç¼“å­˜çš„åˆ†å±‚ç»“æœ
	layersValid   atomic.Bool // åˆ†å±‚ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
}

// NewDAG ä»æè¿°æ„å»ºï¼Œè¿”å›ç¯çš„å…·ä½“è·¯å¾„ï¼ˆæ–¹ä¾¿å‰ç«¯é«˜äº®ï¼‰
func NewDAG(desc []Desc) (*DAG, error) {
	_, cancel := context.WithCancel(context.Background())
	d := &DAG{
		nodes:     make(map[ID]*Node, len(desc)),
		failed:    atomic.Bool{},
		cancelAll: cancel,
	}
	// 1. å»ºèŠ‚ç‚¹
	for _, n := range desc {
		if _, exists := d.nodes[n.ID]; exists {
			return nil, fmt.Errorf("node %s duplicated", n.ID)
		}
		d.nodes[n.ID] = &Node{
			ID:           n.ID,
			Mode:         n.Mode,
			Runner:       n.Runner,
			Successors:   make(map[ID]*Node),
			Predecessors: make(map[ID]*Node),
			doneCh:       make(chan struct{}),
			policy:       n.Policy,
		}
	}
	// 2. å†å»ºè¾¹ï¼ˆä¾èµ– = çˆ¶ â†’ å­ï¼‰
	for _, dsc := range desc {
		to := d.nodes[dsc.ID] // è‡ªå·±ï¼ˆå­ï¼‰
		for _, fromID := range dsc.Deps {
			if strings.TrimSpace(fromID) == "" {
				continue
			}
			if fromID == dsc.ID { //æ„å»ºæ—¶æ£€æµ‹è‡ªç¯
				return nil, fmt.Errorf("self-loop detected: node %s depends on itself", dsc.ID)
			}
			from, ok := d.nodes[fromID]
			if !ok {
				return nil, fmt.Errorf("dependency %s not found", fromID)
			}
			// æ­£ç¡®æ–¹å‘ï¼šçˆ¶ â†’ å­
			from.Successors[dsc.ID] = to
			to.Predecessors[fromID] = from
		}
	}
	// 3. ç¯æ£€æµ‹ï¼ˆKahnï¼‰
	if cycle := d.findCycle(); cycle != nil {
		return nil, fmt.Errorf("cycle detected: %v", cycle)
	}
	// åˆå§‹åŒ–ç¼“å­˜
	d.invalidateCache()
	return d, nil
}

// Kahn ç®—æ³•è¿”å›ç¯çš„èŠ‚ç‚¹åºåˆ—ï¼ˆè‹¥æ— ç¯è¿”å› nilï¼‰
func (d *DAG) findCycle() []ID {
	d.mu.RLock() // ğŸ‘ˆ åªè¯»æ“ä½œï¼Œç”¨ RLock æ›´é«˜æ•ˆ
	defer d.mu.RUnlock()
	return d.findCycleLocked() // å§”æ‰˜ç»™å·²åŠ é”ç‰ˆæœ¬
}

// AddNode è¿è¡Œæ—¶åŠ èŠ‚ç‚¹ï¼ˆå¿…é¡»æ— ç¯ï¼‰
func (d *DAG) AddNode(n *Node) error {
	d.mu.Lock()
	defer d.mu.Unlock()
	if _, ok := d.nodes[n.ID]; ok {
		return fmt.Errorf("node %s exists", n.ID)
	}
	//é˜²å¾¡æ€§åˆå§‹åŒ–
	if n.doneCh == nil {
		n.doneCh = make(chan struct{})
	}
	d.nodes[n.ID] = n
	if cycle := d.findCycleLocked(); cycle != nil {
		delete(d.nodes, n.ID)
		return fmt.Errorf("add node introduces cycle: %v", cycle)
	}
	// æ·»åŠ èŠ‚ç‚¹åï¼Œä½¿ç¼“å­˜å¤±æ•ˆ
	d.invalidateCache()
	return nil
}

// AddEdge åŠ è¾¹ï¼ˆåŒå‘ç»´æŠ¤ï¼‰
func (d *DAG) AddEdge(from, to ID) error {
	if from == to { // ç¦æ­¢è‡ªç¯
		return fmt.Errorf("self-loop not allowed:%s -> %s", from, to)
	}
	d.mu.Lock()
	defer d.mu.Unlock()
	f, ok1 := d.nodes[from]
	t, ok2 := d.nodes[to]
	if !ok1 || !ok2 {
		return fmt.Errorf("node not found")
	}
	// from !=to ,æ‰€ä»¥ få’Œt æ˜¯ä¸åŒçš„èŠ‚ç‚¹ï¼Œå¯ä»¥å®‰å…¨æ·é”
	f.mu.Lock()
	t.mu.Lock()
	defer f.mu.Unlock()
	defer t.mu.Unlock()
	f.Successors[to] = t
	t.Predecessors[from] = f
	if cycle := d.findCycleLocked(); cycle != nil {
		delete(f.Successors, to)
		delete(t.Predecessors, from)
		return fmt.Errorf("add edge introduces cycle: %v", cycle)
	}
	// æ·»åŠ è¾¹åï¼Œä½¿ç¼“å­˜å¤±æ•ˆ
	d.invalidateCache()
	return nil
}

// ToGraphviz å¯¼å‡º DOT
func (d *DAG) ToGraphviz() string {
	d.mu.RLock()
	defer d.mu.RUnlock()
	b := &strings.Builder{}
	b.WriteString("digraph G {\n")
	for _, n := range d.nodes {
		shape := map[RunMode]string{
			RunModeSerial:   "box",
			RunModeParallel: "ellipse",
			RunModeMixed:    "diamond",
		}[n.Mode]
		b.WriteString("  ")
		b.WriteString(n.ID)
		b.WriteString(" [label=\"")
		b.WriteString(n.ID)
		b.WriteString("\",shape=")
		b.WriteString(shape)
		b.WriteString("]; \n")
		for to := range n.Successors {
			b.WriteString("  ")
			b.WriteString(n.ID)
			b.WriteString(" -> ")
			b.WriteString(to)
			b.WriteString(";\n")
		}
	}
	b.WriteString("}\n")
	return b.String()
}

// ToMermaid å¯¼å‡º Mermaid flowchart
func (d *DAG) ToMermaid() string {
	d.mu.RLock()
	defer d.mu.RUnlock()
	b := &strings.Builder{}
	b.WriteString("graph TD;\n")
	for _, n := range d.nodes {
		for to := range n.Successors {
			b.WriteString(n.ID)
			b.WriteString(" --> ")
			b.WriteString(to)
			b.WriteString(";\n")
		}
	}
	return b.String()
}

// Snapshot è¿”å›å½“å‰å·²ç»“æŸèŠ‚ç‚¹
func (d *DAG) Snapshot() map[ID]State {
	d.mu.RLock()
	defer d.mu.RUnlock()
	m := make(map[ID]State, len(d.nodes))
	for id, n := range d.nodes {
		m[id] = State(n.State.Load())
	}
	return m
}

// LoadSnapshot æ¢å¤çŠ¶æ€ï¼ˆé‡å¯åï¼‰
func (d *DAG) LoadSnapshot(snap map[ID]State) {
	d.mu.Lock()
	defer d.mu.Unlock()
	for id, state := range snap {
		if n, ok := d.nodes[id]; ok {
			n.State.Store(uint32(state))
		}
	}
}

// ======== æ–°å¢è¾…åŠ©å‡½æ•°ï¼šæ‰§è¡Œ Kahn ç®—æ³•ï¼Œè¿”å›æ‹“æ‰‘åºå’Œæ˜¯å¦æˆåŠŸ ========
// åœ¨å·²æŒæœ‰ d.mu.RLock() æˆ– d.mu.Lock() çš„æƒ…å†µä¸‹è°ƒç”¨
func (d *DAG) kahnSortLocked() ([]ID, bool) {
	inDegree := make(map[ID]int, len(d.nodes))
	for id := range d.nodes {
		inDegree[id] = 0
	}
	// ç»Ÿè®¡å…¥åº¦
	for _, n := range d.nodes {
		for to := range n.Successors {
			inDegree[to]++
		}
	}
	// åˆå§‹åŒ–é˜Ÿåˆ—ï¼ˆå…¥åº¦ä¸º0çš„èŠ‚ç‚¹ï¼‰
	q := make([]ID, 0, len(d.nodes))
	for id, deg := range inDegree {
		if deg == 0 {
			q = append(q, id)
		}
	}
	// Kahn ä¸»å¾ªç¯
	order := make([]ID, 0, len(d.nodes))
	cnt := 0
	for len(q) > 0 {
		cur := q[0]
		q = q[1:]
		order = append(order, cur)
		cnt++
		for to := range d.nodes[cur].Successors {
			inDegree[to]--
			if inDegree[to] == 0 {
				q = append(q, to)
			}
		}
	}
	// æˆåŠŸå½“ä¸”ä»…å½“å¤„ç†äº†æ‰€æœ‰èŠ‚ç‚¹
	return order, cnt == len(d.nodes)
}

// findCycleLocked æŸ¥æ‰¾æ˜¯å¦å­˜åœ¨ç¯ã€‚è‹¥æœ‰ç¯ï¼Œè¿”å›ç¯åºåˆ—ï¼ˆä»å¶å­åˆ°æ ¹ï¼‰
func (d *DAG) findCycleLocked() []ID {
	_, ok := d.kahnSortLocked()
	if ok {
		return nil // æ— ç¯
	}
	// æœ‰ç¯ï¼Œç”¨ DFS æ‰¾å‡ºå…·ä½“ç¯
	visited := make(map[ID]bool, len(d.nodes))
	onStack := make(map[ID]bool, len(d.nodes))
	var cycle []ID
	var dfs func(ID) bool
	dfs = func(id ID) bool {
		visited[id] = true
		onStack[id] = true
		cycle = append(cycle, id)
		for to := range d.nodes[id].Successors {
			//æ˜¾ç¤ºæ£€æµ‹è‡ªç¯
			if to == id {
				cycle = []ID{id}
				return true
			}
			if !visited[to] {
				if dfs(to) {
					return true
				}
			} else if onStack[to] {
				// æ‰¾åˆ°ç¯èµ·ç‚¹ï¼Œæˆªå–
				for i, x := range cycle {
					if x == to {
						cycle = cycle[i:]
						return true
					}
				}
			}
		}
		// å›æº¯
		cycle = cycle[:len(cycle)-1]
		onStack[id] = false
		return false
	}
	for id := range d.nodes {
		if !visited[id] {
			if dfs(id) {
				return cycle
			}
		}
	}
	return nil
}

// TopoSort ======== æ–°å¢ï¼šTopoSort è¿”å›æ‹“æ‰‘åº ========
// çº¿ç¨‹å®‰å…¨ï¼Œåªè¯»æ“ä½œ
func (d *DAG) TopoSort() ([]ID, error) {
	d.mu.RLock()
	defer d.mu.RUnlock()
	order, ok := d.kahnSortLocked()
	if !ok {
		return nil, fmt.Errorf("graph contains cycle, cannot perform topological sort")
	}
	return order, nil
}

// RemoveNode åˆ é™¤èŠ‚ç‚¹åŠå…¶æ‰€æœ‰ç›¸å…³è¾¹ï¼Œå¹¶å¼ºåˆ¶ä¿è¯ DAG æ— ç¯
// å¦‚æœèŠ‚ç‚¹ä¸å­˜åœ¨ï¼Œè¿”å› error
// åˆ é™¤åä¼šé‡æ–°æ£€æµ‹æ•´ä¸ªå›¾æ˜¯å¦æ— ç¯ï¼Œç¡®ä¿å¼ºä¸€è‡´æ€§
func (d *DAG) RemoveNode(id ID) error {
	d.mu.Lock()
	defer d.mu.Unlock()
	node, ok := d.nodes[id]
	if !ok {
		return fmt.Errorf("node %s not found", id)
	}
	// 1. ä»æ‰€æœ‰å‰é©±èŠ‚ç‚¹çš„ Successors ä¸­ç§»é™¤è‡ªå·±
	for predID := range node.Predecessors {
		if pred, ok := d.nodes[predID]; ok {
			delete(pred.Successors, id)
		}
	}
	// 2. ä»æ‰€æœ‰åç»§èŠ‚ç‚¹çš„ Predecessors ä¸­ç§»é™¤è‡ªå·±
	for succID := range node.Successors {
		if succ, ok := d.nodes[succID]; ok {
			delete(succ.Predecessors, id)
		}
	}
	// 3. ä»å›¾ä¸­åˆ é™¤è‡ªå·±
	delete(d.nodes, id)
	// 4. å¼ºä¿è¯ï¼šåˆ é™¤åé‡æ–°æ£€æµ‹ç¯ï¼
	//  è™½ç„¶åˆ é™¤ä¸ä¼šå¼•å…¥ç¯ï¼Œä½†ä¸ºäº†ç³»ç»Ÿå¼ºä¸€è‡´æ€§ï¼Œå¿…é¡»éªŒè¯ï¼
	if cycle := d.findCycleLocked(); cycle != nil {
		// ç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼å¦‚æœå‘ç”Ÿï¼Œè¯´æ˜å›¾ç»“æ„æœ‰éšè— bug
		return fmt.Errorf("internal error: DAG has cycle after removing node %s: %v", id, cycle)
	}
	// åˆ é™¤èŠ‚ç‚¹åï¼Œä½¿ç¼“å­˜å¤±æ•ˆ
	d.invalidateCache()
	return nil
}

// SSnapshot ç”Ÿæˆå½“å‰ DAG çš„ç»“æ„å¿«ç…§
func (d *DAG) SSnapshot() DAGSnapshot {
	d.mu.RLock()
	defer d.mu.RUnlock()
	var nodes []NodeSnapshot
	for _, node := range d.nodes {
		deps := make([]ID, 0, len(node.Predecessors))
		for depID := range node.Predecessors {
			deps = append(deps, depID)
		}
		// ä¿æŒé¡ºåºä¸€è‡´ï¼Œä¾¿äºå¯¹æ¯”
		sort.Slice(deps, func(i, j int) bool {
			return deps[i] < deps[j]
		})
		nodes = append(nodes, NodeSnapshot{
			ID:   node.ID,
			Deps: deps,
			Mode: node.Mode,
		})
	}
	// ä¿æŒèŠ‚ç‚¹é¡ºåºä¸€è‡´
	sort.Slice(nodes, func(i, j int) bool {
		return nodes[i].ID < nodes[j].ID
	})
	//åªéœ€è¦å½“å‰çš„Nodeçš„ç»“æ„ä¿¡æ¯
	return DAGSnapshot{
		Nodes: nodes,
	}
}

// GetStructuralMD5 ä¸º DAG ç”Ÿæˆç»“æ„ MD5 ç‰ˆæœ¬å·
func (d *DAG) GetStructuralMD5() (string, error) {
	snap := d.SSnapshot() // ä½¿ç”¨ä¹‹å‰å®šä¹‰çš„ Snapshot
	// åºåˆ—åŒ–ä¸º JSONï¼ˆç¡®ä¿ç»“æ„ç¨³å®šï¼‰
	data, err := json.Marshal(snap)
	if err != nil {
		return "", err
	}
	// è®¡ç®— MD5ï¼Œé™„å¸¦æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
	hash := md5.Sum(data)
	return fmt.Sprintf("%d-%x", time.Now().Unix(), hash), nil
}

// invalidateCache ä½¿æ‰€æœ‰ç¼“å­˜å¤±æ•ˆ
func (d *DAG) invalidateCache() {
	d.topologyValid.Store(false)
	d.layersValid.Store(false)
}

// TopoSortCached è¿”å›ç¼“å­˜çš„æ‹“æ‰‘åºï¼Œå¦‚æœç¼“å­˜æ— æ•ˆåˆ™é‡æ–°è®¡ç®—
func (d *DAG) TopoSortCached() ([]ID, error) {
	// å…ˆæ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
	if d.topologyValid.Load() {
		return d.topologyCache, nil
	}

	// ç¼“å­˜æ— æ•ˆï¼Œé‡æ–°è®¡ç®—
	d.mu.Lock()
	defer d.mu.Unlock()

	// åŒé‡æ£€æŸ¥ï¼Œé¿å…å¤šä¸ªgoroutineåŒæ—¶é‡æ–°è®¡ç®—
	if d.topologyValid.Load() {
		return d.topologyCache, nil
	}

	order, ok := d.kahnSortLocked()
	if !ok {
		return nil, fmt.Errorf("graph contains cycle, cannot perform topological sort")
	}

	// æ›´æ–°ç¼“å­˜
	d.topologyCache = order
	d.topologyValid.Store(true)

	return order, nil
}

// topoLayersCached è¿”å›ç¼“å­˜çš„åˆ†å±‚ç»“æœï¼Œå¦‚æœç¼“å­˜æ— æ•ˆåˆ™é‡æ–°è®¡ç®—
func (d *DAG) topoLayersCached() ([][]ID, error) {
	// å…ˆæ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
	if d.layersValid.Load() {
		return d.layersCache, nil
	}

	// ç¼“å­˜æ— æ•ˆï¼Œé‡æ–°è®¡ç®—
	d.mu.Lock()
	defer d.mu.Unlock()

	// åŒé‡æ£€æŸ¥
	if d.layersValid.Load() {
		return d.layersCache, nil
	}

	layers, err := d.topoLayersLocked()
	if err != nil {
		return nil, err
	}

	// æ›´æ–°ç¼“å­˜
	d.layersCache = layers
	d.layersValid.Store(true)

	return layers, nil
}

// topoLayersLocked åœ¨å·²æŒæœ‰é”çš„æƒ…å†µä¸‹è®¡ç®—åˆ†å±‚æ‹“æ‰‘åº
func (d *DAG) topoLayersLocked() ([][]ID, error) {
	inDegree := make(map[ID]int, len(d.nodes))
	for id := range d.nodes {
		inDegree[id] = 0
	}
	for _, n := range d.nodes {
		for to := range n.Successors {
			inDegree[to]++
		}
	}
	var layers [][]ID
	var q []ID
	for id, deg := range inDegree {
		if deg == 0 {
			q = append(q, id)
		}
	}
	for len(q) > 0 {
		curLevel := q
		layers = append(layers, curLevel)
		q = nil
		for _, id := range curLevel {
			for to := range d.nodes[id].Successors {
				inDegree[to]--
				if inDegree[to] == 0 {
					q = append(q, to)
				}
			}
		}
	}
	return layers, nil
}
